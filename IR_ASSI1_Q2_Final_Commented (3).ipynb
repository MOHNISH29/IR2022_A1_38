{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3c434f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "import re\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43d6303",
   "metadata": {},
   "source": [
    "# Retrieving data from files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "63a0e4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = []\n",
    "data = []\n",
    "for filename in os.listdir(\"data_folder\"):\n",
    "    file_names.append(filename)\n",
    "    \n",
    "    try:\n",
    "            f = open(\"data_folder/\"+filename , encoding='utf8')\n",
    "            var=f.read().replace('\\n',\" \")\n",
    "            data.append(var)\n",
    "            \n",
    "    except Exception as e:\n",
    "            f = open(\"data_folder/\"+filename , encoding='unicode_escape')\n",
    "            var=f.read().replace('\\n',\" \")\n",
    "            data.append(var)\n",
    "            \n",
    "    f.close();\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0511e448",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "edb48fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(d):\n",
    "    no_punc = []\n",
    "    d_lower=d.lower()\n",
    "    \n",
    "    nltk_tokens = nltk.word_tokenize(d_lower)\n",
    "    \n",
    "    stop_words_removed = []\n",
    "    for w in nltk_tokens:\n",
    "        if w not in stop_words:\n",
    "            stop_words_removed.append(w)\n",
    "    \n",
    "    \n",
    "    new_words = []\n",
    "    for x in stop_words_removed:\n",
    "        if(x.isalnum() and x!=\" \"):\n",
    "            new_words.append(x)\n",
    "        \n",
    "        \n",
    "    return new_words\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "42fd2f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_data = []\n",
    "for d in data:\n",
    "    data_new = preprocessing(d)\n",
    "    preprocessed_data.append(data_new)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27dc00fb",
   "metadata": {},
   "source": [
    "# Creating Positional indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6b0196f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_indexing(dict_position , file_id  , data):\n",
    "    \n",
    "    for position , token in enumerate(data):\n",
    "        \n",
    "        \n",
    "        if token in dict_position:\n",
    "            dict_position[token][0] +=1\n",
    "            if file_id in dict_position[token][1]:\n",
    "                dict_position[token][1][file_id].append(position)\n",
    "                \n",
    "            else:\n",
    "                dict_position[token][1][file_id] = [position]\n",
    "                \n",
    "        else:\n",
    "            new_dict = {}\n",
    "            new_dict[file_id] = [position]\n",
    "            dict_position[token] = [1 , new_dict]\n",
    "            \n",
    "        \n",
    "    return dict_position\n",
    "                \n",
    "        \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b6cbfd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_position = {}\n",
    "for i in range(len(preprocessed_data)):\n",
    "     dict_position = positional_indexing(dict_position , i  , preprocessed_data[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af2e969",
   "metadata": {},
   "source": [
    "# Loading positional indexing datastructure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "402be258",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_datastructure():\n",
    "    ds = open(\"postings2.pkl\" , \"rb\")\n",
    "    postings = pickle.load(ds)\n",
    "    \n",
    "    return postings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e4b2be0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_stemming(q):\n",
    "    stemmer = PorterStemmer()\n",
    "    stemmed = []\n",
    "    for word in q:\n",
    "        stemmed.append(stemmer.stem(word))\n",
    "    return stemmed  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75433f0",
   "metadata": {},
   "source": [
    "# Saving positional indexing datastructure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7bff2c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "posting_datastructure = open(\"postings2.pkl\" , \"wb\")\n",
    "pickle.dump(dict_position ,posting_datastructure )\n",
    "posting_datastructure.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3ab66504",
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection(posting1 , posting2 , diff):\n",
    "    len1 = len(posting1[1].keys())\n",
    "    len2 = len(posting2[1].keys())\n",
    "    #len1 = posting1[0]\n",
    "    #len2 = posting2[0]\n",
    "    doc_ids = []\n",
    "    \n",
    "    if(len1<=len2):\n",
    "        ps1 = posting1\n",
    "        ps2 = posting2\n",
    "    \n",
    "    else:\n",
    "        ps1 = posting2\n",
    "        ps2 = posting1\n",
    "        diff = -diff\n",
    "    \n",
    "    for file_id in ps1[1].keys():\n",
    "        if file_id in ps2[1].keys():\n",
    "            \n",
    "            for pos1 in ps1[1][file_id]:\n",
    "                for pos2 in ps2[1][file_id]:\n",
    "                    if pos2-pos1== diff :\n",
    "                        if file_id not in doc_ids:\n",
    "                            doc_ids.append(file_id)\n",
    "                        break\n",
    "    \n",
    "    return doc_ids\n",
    "                        \n",
    "               "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411bce87",
   "metadata": {},
   "source": [
    "# Searching Phrase Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d7db9115",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_phrase_query(query):\n",
    "    \n",
    "    posting_ds = load_datastructure()\n",
    "    no_phrase=0\n",
    "    flag = 0\n",
    "    postings = []\n",
    "    for word in query :\n",
    "        if word in posting_ds:\n",
    "            postings.append(posting_ds[word])\n",
    "        else:\n",
    "            flag=1\n",
    "            break\n",
    "            \n",
    "    alldocs = []\n",
    "    if(flag==1):\n",
    "        print(\"1\")\n",
    "        print(\"Given phrase is not present\")\n",
    "    else:\n",
    "        for i in range(len(postings)-1):\n",
    "            j=i+1\n",
    "            for j in range(len(postings)):\n",
    "                docs = []\n",
    "                x = j-i\n",
    "                docs = intersection(postings[i], postings[j] , x)\n",
    "                if(len(docs)!=0):\n",
    "                    alldocs.append(docs)\n",
    "                else:\n",
    "                    print(\"2\")\n",
    "                    print(\"Given phrase is not present\")\n",
    "                    no_phrase=1\n",
    "                    break\n",
    "            if no_phrase == 1:\n",
    "                break\n",
    "            \n",
    "        if no_phrase == 0:\n",
    "            final_result = set.intersection(*[set(x) for x in alldocs])\n",
    "            end_result = []\n",
    "            end_result = list(final_result)\n",
    "            if(len(end_result) == 0):\n",
    "                print(\"3\")\n",
    "                print(\"Given phrase is not present\")\n",
    "            else:\n",
    "                print(\"Number of documents retrieved:\")\n",
    "                print(len(end_result))\n",
    "                print(\"Names of documents are:\")\n",
    "                for f in end_result:\n",
    "                    print(file_names[f])\n",
    "        \n",
    "                return end_result\n",
    "        else:\n",
    "            end_result=\"nothing\"\n",
    "            return end_result\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f306e11d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter your queryWoods World Championship Chili\n",
      "Number of documents retrieved:\n",
      "2\n",
      "Names of documents are:\n",
      "woods.txt\n",
      "chili.txt\n"
     ]
    }
   ],
   "source": [
    "query = input(\"Please enter your query\")\n",
    "query = preprocessing(query)\n",
    "if(len(query)==1):\n",
    "    posting_ds = load_datastructure()\n",
    "    word = query[0]\n",
    "    if word in posting_ds:\n",
    "        d = posting_ds[word][1].keys()\n",
    "        d = list(d)\n",
    "        print(\"Number of documents retrieved:\")\n",
    "        print(len(d))\n",
    "        print(\"Names of documents are:\")\n",
    "        for f in d:\n",
    "            print(file_names[f])\n",
    "    else:\n",
    "        print(\"phrase not present!\")\n",
    "else:\n",
    "        search_phrase_query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f59f1ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
